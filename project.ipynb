{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task for Course: DLBAIPNLP01 – Project: NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imporing all neccessary libraries we gonna use. Could be done at the area where the library is really needed, but I prefer to have them all combined to be easier to observe if some are missing or unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load all datasets we need to work with, this include the stopwords list and the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Thomas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# download the stopword set\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('movie_comment_data_labeled/IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do some initial investigation and descriptive statistics on the data we working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of words: 4\n",
      "Maximum number of words: 2470\n",
      "Average number of words: 231.16\n"
     ]
    }
   ],
   "source": [
    "# count words in the text\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "df['Word_Counts'] = df['review'].apply(count_words)\n",
    "\n",
    "# Calculate minimum, maximum, and average number of words\n",
    "min_words = df['Word_Counts'].min()\n",
    "max_words = df['Word_Counts'].max()\n",
    "average_words = df['Word_Counts'].mean()\n",
    "\n",
    "print(f\"Minimum number of words: {min_words}\")\n",
    "print(f\"Maximum number of words: {max_words}\")\n",
    "print(f\"Average number of words: {average_words:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For working later with the text we need the stemmer for the stemming. Previous build of models show this is the best one used for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "# final function after evaluation. it prepares the text for working with it later. This includes \"normalize\" the text. make all lower case, remove puntuation, split, remove stoüwords and stemming\n",
    "def preprocess_text_stem(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    # Stemming\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "    return ' '.join(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply out text prepreccessing, split the dataset by the default size and set a random_state so we can reproduce the results each time. Can be removed when we want some variation and get a possible slightly better model.\n",
    "\n",
    "prepare the vectorization, train the model and report the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8863\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.88      4961\n",
      "    positive       0.87      0.90      0.89      5039\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(preprocess_text_stem)\n",
    "\n",
    "# Prepare the common training split\n",
    "X = df['review']\n",
    "y = df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize our vectorization we want to stick with\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Model Training\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test_vec)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create another function to get the prediction. So we don´t need to call the preprecessing and vectorization everytime we want to test the model manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    # Preprocess the text\n",
    "    preprocessed_text = preprocess_text_stem(text)\n",
    "    # Transform the text\n",
    "    text_vector = vectorizer.transform([preprocessed_text])\n",
    "    # Predict sentiment\n",
    "    prediction = model.predict(text_vector)\n",
    "    \n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets do some predections to test the model on unseen data on own. This sets we can rate manually and see the outcome. We will go through 4 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: prediction should be negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" This movie disappointed me. The actors should all be retired! The laughs were flat. I was expecting big laughs. Nope.\"\n",
    "res = predict_sentiment(text)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second: prediction should be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" This was an overall exceptional movie, that reignites the franchise all over for me. Seeing Eddie and the cast that made the orginal movies years later still going at it was great. The throwbacks, the comedy and the connection between the actors makes this film work and very enjoyable.  \"\n",
    "res = predict_sentiment(text)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third: prediction should be negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" inception was dumb. no dreamlike phantasy world but a standard action flick with lots of shooting and explosions instead \"\n",
    "res = predict_sentiment(text)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourth: prediction should be negative. More complex and long one to test it more intense. It also have contracting information in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \" Nolan has done it again. He has made a one-dimensional film that people only like because of its false, high standards. Most Nolan films always seem to the casual film viewer like a kind of sophisticated and complex niche film. However, the complexity of a Nolan film is usually affected. And that is the case here too. Nolan tells a simple, one-dimensional story and deliberately leaves some questions open that he only answers later. This has nothing to do with complexity, but only with cheap card tricks. This makes the plot seem complex and confusing. Nolan's films also do not live from the story or the development of the characters, which in this film only takes place as an alibi, but from action sequences, baroque and cheap music and explosions, so they are just as cheap as, for example, the Marvel films. However, some wannabe intellectual part-time film fans sit on their couch and think they have just seen the fourth 3 Colors film, ergo they think they have just seen a sophisticated masterpiece and are surprised at how much they enjoyed this oh-so-complex effect. Over-motivated, they then tell their friends and relatives about the brilliantly complex Inception and how sophisticated their taste is. So: Inception is absolutely overrated, the film is in no way sophisticated and no better than any other contemporary action film. It remains a simple action film full of temporal causality strips, explosions and card tricks. A film for people who think that Hans Zimmer is the most brilliant composer of our time because his pieces have extreme crescendos. The man can't even read music. Well, Inception is still NOT terrible. DiCaprio, Page, Kaine and co. deliver decent performances, the film is not bad visually and the action sequences are well choreographed. However, it is not the film for the history books that it is too often sold as. \"\n",
    "\n",
    "res = predict_sentiment(text)\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project-Gv_7p7uA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
